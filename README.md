# Script de recalcul du calque de plantabilit√©

Ces scripts ont pour objectif de calculer les indices de plantabilit√© sur l'ensemble du territoire de la M√©tropole de Lyon.

## Installation

* Installez **Python 3.8.10** (version recommand√©e)
* Clonez ce projet sur votre instance
```bash
git clone https://forge.grandlyon.com/erasme/script-recalcul-calque.git
```
* Pr√©parer vos fichiers source de donn√©es en fonction de vos param√®trage dans la table metadatas. Les donn√©es sources de la M√©tropole n'√©tant pas toutes en OpenData, elles ne sont pas disponible en t√©l√©chargement. Merci de nous contacter √† l'adresse suivante : [datagora@lists.erasme.org](mailto:datagora@lists.erasme.org)
* Copiez ces fichiers source dans le dossier `file_data/` √† la racine du projet
* Cr√©ez et configurez le fichier `.env` √† partir du fichier `.env.example` (Cf. Configuration avanc√©e)
```bash
cp .env.example .env
nano .env
```
* Installez les d√©pendances sur votre environnement Python
```bash
pip install -r requirements.txt
```
<i>Certains packages √©tant difficilement installables sur Windows, il est parfois n√©cessaire de passer par pipwin...</i>

* Lancer une premi√®re fois le script pour afficher la documentation
```bash
python - main.py
```

**Bravo ! Vous √™tes d√©sormais pr√™t √† lancer un nouveau calcul du calque de plantabilit√© !** üéâ

## Utilisation

La documentation du script vous aidera √† comprendre les arguments √† passer pour lancer chaque √©tape du calcul :

```bash
$ python - main.py help

Args:
  initCommunes                                        Insert Communes in database from a geoJSON file path (with geometry and insee column)
  initGrid <gridSize: int, inseeCode: int>            Generate with the size defined and insert Grid in database merged from a bounding box
                                                      Can be launch on certain "communes" with one <inseeCode> or in all territory by default (no parameter)
  initDatas                                           Make treatments on the datas from informations in metadatas table
  computeFactors <inseeCode: int>                     Compute the factors area on each tile with database informations. 
                                                      Can be launch on certain "communes" with one <inseeCode> or in all territory by default (no parameter)
  computeIndices                                      Compute the plantability indices on each tile with database informations. 
  computeAll <gridSize: int, listInseeCode: int>      Generate all the plantability layer (launch all previous steps). 
                                                      List of inseeCode must be separated with comma (,) and without space (e.g. python - main.py 5 69266,69388,69256) 
                                                      but you can launch treatments for only one commune (e.g. python - main.py 5 69266)
  help                                                Show this documentation
```

L'ordre complet de lancement des √©tapes (effectu√© avec `computeAll`) est le suivant :

```bash
initCommunes
initGrid (30 m√®tres par d√©faut et sur toutes les communes)
initDatas
computeFactors (sur toutes les communes)
computeIndices (sur toutes les communes)
```

<i>Si toutes ces √©tapes se sont bien d√©roul√©es, c'est que les donn√©es sont d√©sormais pr√™tes √† √™tre exploit√©e au travers d'un serveur cartographique (GeoServer par exemple).</i>

<i>Pour cela, il faudra configurer une nouvelle couche sur la table `tiles` de la base de donn√©es. (Cf. Documentation > Mod√®le logique de donn√©es)</i>

## Configuration avanc√©e

* D√©tail de configuration des attributs du fichier .env
```bash
# DB settings
DB_HOST="XXXXXXXXXXXXXX"      # Nom de domaine ou adresse IP de connexion √† la base de donn√©es
DB_PORT=5432                  # Port de connexion √† la base de donn√©es
DB_USER="XXXXXXXXXXXXXX"      # Nom d'utilisateur de connexion √† la base de donn√©es
DB_PWD="XXXXXXXXXXXXXX"       # Mot de passe de connexion √† la base de donn√©es
DB_NAME="XXXXXXXXXXXXXX"      # Nom de la base de donn√©es (exemple : calque_planta)
DB_SCHEMA="XXXXXXXXXXXXXX"    # Sch√©ma PostgreSQL dans lequel se trouve la base de donn√©es
# Python settings
PYTHON_LAUNCH="python"        # Commande bash utilis√©e pour le lancement des sous scripts Python (peut √™tre remplac√© par python3 si n√©cessaire)
# Others settings
TARGET_PROJ="EPSG:2154"       # Projection cible utilis√©e pour r√©aliser les traitements de donn√©es
REMOVE_TEMP_FILE=False        # Permet de supprimer les fichiers temporaires g√©n√©r√©s lors des traitements de donn√©es
SKIP_EXISTING_DATA=True       # Permet de passer automatiquement √† l'√©tape suivante lorsque la donn√©e trait√©e existe d√©j√† en base
ENABLE_TRUNCATE=False         # Permet de supprimer automatiquement la donn√©e lors de son traitement si elle existe d√©j√† en base
```

## Documentation compl√®te du projet

L'architecture logicielle cible pour le fonctionnement du projet utilise les briques technologiques suivante : 
* Une instance de calcul du calque de plantabilit√© (Serveur Linux / Python 3.8.X)
* Une base de donn√©es PostgreSQL 11 (l'extension PostGIS est un plus)
* Un serveur cartographique (GeoServer par exemple)
* Une plateforme web de visualisation (Angular/Nest dans notre cas)

Dans le cadre de notre exp√©rimentation, nous avons fait le choix de "containeriser" l'instance de calcul du calque, ainsi que le front et back de la plateforme web.

Vous trouverez le d√©tail de ce projet sur les documents suivants :
* [Notice d'utilisation du calque](https://documents.exo-dev.fr/notice_utilisation_calque_plantabilite_lyon_V1.pdf)
* [Documentation g√©n√©rale du projet (√† venir)]()
* [Documentation technique du projet (√† venir)]()
* [Mod√®le logique de donn√©es (MLD)](https://documents.exo-dev.fr/metropole/MLD_calque_plantabilite_lyon.png)
* [Liste des donn√©es utilis√©es et traitements associ√©s](https://www.figma.com/file/jE0JR0PiNbDU9ShK2V2tnZ/Process-data-calque-de-plantabilit%C3%A9?node-id=0%3A1)

## Cr√©dits

* Author: Romain MATIAS
* Copyright: Copyright 2022, EXO-DEV x ERASME, M√©tropole de Lyon
* Description: Script de cr√©ation d'un calque de plantabilit√© pour la M√©tropole de Lyon
* Credits: Romain MATIAS, Natacha SALMERON, Anthony ANGELOT
* Date: 06/07/2022
* License: MIT
* Version: 1.0.0
* Maintainer: Romain MATIAS
* Email: contact@exo-dev.fr ou info@erasme.org
* Status: Exp√©rimentation

## Int√©gration continue & D√©ploiement

L'int√©gration continue et le d√©ploiement continue fonctionne de fa√ßon semi-automatique √† partir de la plateforme Gitlab (Forge). 
La phase de build est r√©alis√©e automatiquement dans la Gitlab √† chaque commit sur la branche.
La seule branche qui n'est pas build√©e est mla branche prot√©g√©e : __main__.

Ce d√©p√¥t est structur√© en 4 branches.

- __Main__ : La derni√®re version stable du code. **Cette branche n'est jamais ni build√©e nu d√©ploy√©e, Il s'agit de la branche de r√©f√©rence et elle est prot√©g√©e**.
             Les mises √† jour y sont contr√¥l√©es et effectu√©es √† chaque nouvelle version fonctionnlle, test√©e et stable du code. 
- __develop__ : Branche d√©veloppement pour les nouvelles fonctionnalit√©s. **Cette branche est build√©e et d√©ploy√©e sur le namespace de d√©veloppement ns-arb-d01**.
- __rec__ : Branche d'int√©gration et de recette des nouvelles fonctionnalit√©s. **Cette branche est build√©e et d√©ploy√©e sur le namespace de recette ns-arb-r01**.
- __pro__ : Branche de production de l'application. **Cette branche est build√©e et d√©ploy√©e sur le namespace de production ns-arb-p01**.
            Le build et le d√©ploiement de cette branche est manuel.

## Build

### Configuration de Gitlab
Sous la rubrique Settings > CI/CD > Variables, chaque variable ci-dessous doit √™tre initialis√©e pour chaque environnement :

#### DB_PARAMS
- Type : File

- Valeur :
  
> export POSTGRES_DB=calque_planta_temp
> export POSTGRES_PASSWORD=xxxxx
> export POSTGRES_PORT=5432
> export POSTGRES_SERVER=calqul-db-service
> export POSTGRES_USER=calqul
> export POSTGRES_SCHEMA=base
> export POSTGRES_EXTERNAL_PORT=300xx

#### DEPLOY_RUNNER

-  Type : Variable

- Valeur : ns-arb-x01

#### KUBECONFIG

- Type : File

- Valeur : (catte valeur est r√©cu√©p√©r√©e √† partir du manager Openshift)
  
> apiVersion: v1
> clusters:
>   - cluster:
>       certificate-authority-data: 
>       ...=
>       server: 'https://api.air.grandlyon.fr:6443'
>     name: 'cluster-interne-pro'
> contexts:
>      ....

#### NAMESPACE_ENV

-  Type : Variable

- Valeur : dev/rec/pro

## Deploy 

### D√©ploiemet d'un Job Openshift
Le d√©ploiement s'appuie sur un job OpenShift plut√¥t qu'un Pod. 
L'int√©r√™t r√©side dans le fait qu'un job se lance, fait ce qu'il a √† faire et s'arr√™te lorsqu'il a fini, avec un code de sortie 0 ou 1.
Il consomme les ressources n√©cessaires le temps de l'ex√©cution de son script, puis s'arr√™te, contrairement au pod qui reste en attente une fois d√©ploy√© et qui est relanc√© s'il tombe.

Doc : 
 - https://cloud.redhat.com/blog/openshift-jobs
 - https://docs.openshift.com/container-platform/4.11/nodes/jobs/nodes-nodes-jobs.html

#### Installation d'un nouvel environnement

1. Cr√©er un nouveau namespace openShift
   1. Cr√©er les PVC sur le mol√®des des PVC existants danss l'environnement de dev.
      - pvc-02-ns-arb-[ENV]-claim : 40Go - cephfs
      - pvc-03-ns-arb-[ENV]-claim : 20Go -  cephfs
   2. Cr√©er un Runner (cf https://guide.air.grandlyon.fr)
   3. R√©cup√©rer le KUBECONFIG
2. Duppliquer toutes les variables Gitlab li√©es √† un environnement
3. Cr√©er le token d'acc√®s au d√©p√¥t des donn√©es cartographiques
   Sous la console OpenShift, menu 'Secrets' copier le Yaml du secret √†rb-data-access-token` et le cr√©er dans le nouveau namspace.

#### Suppression d'un job

 - https://access.redhat.com/documentation/en-us/openshift_container_platform/3.4/html/developer_guide/dev-guide-scheduled-jobs

#### Commandes lanc√©es par le job 

Le job d√©roule calcul en 6 √©tapes, avec un √©tape de mise √† blanc complet de l'environnement (0), et une √©tape de dump du r√©sultat (5).
Apr√®s l'√©tape 1, toutes les autres √©tapes peuvent √™tre relanc√©es √† n'importer quel moment tant qu'on execute tout jusqu'√† la fin.
exemple : si vous relancez 3, fa√Ætes 3,4,5

`cleanup|init-grid|init-datas|compute-factors|compute-indices|dump-datas|all`

0. cleanup => Nettoie les tables de progression, nettoie le cache des tuiles, avant un recalcul complet.
1. init-grid => Initialise la base de donn√©es avec chaque tuile sur tout le territoire.
2. init-datas => Initialise toutes les donn√©es avec chaque facteur.
3. compute-factors => Calcule tous les facteurs.
4. compute-indices => Calcule les indices de chaque tuile.
5. dump-datas => Effectue une sauvegarde de la base de donn√©es.
. all => Lance toutes les √©tapes dans l'ordre d√©crit ci-dessous.

   - main.py initCommunes
   - main.py initGrid
   - main.py initDatas
   - main.py computeFactors
   - main.py computeIndices
   - main.py computeAll
   - main.py help

#### Relancer un Job

 1. Se connecter √† OpenShift
 2. Supprimer le pod correspondant √† l'√©tape du Job. 
 
 >   __Par exemple__, pour l'√©tape `computeFactor`, le nom du job dans OpenShift est `calqul-stage-compute-factors-r01`, 
 >   et le nom du pod associ√© √† ce job est de la forme `calqul-stage-compute-factors-r01-xxxxx`

 3. Dans la pipeline du projet, relancer l'√©tape via l'interface web 

![Listes des √©tapes du calcul](doc/etapes.png)